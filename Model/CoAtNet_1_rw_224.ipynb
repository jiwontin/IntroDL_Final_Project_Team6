{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwUDkwGOVGmnO1zXDQNsK6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mYsWPytCpP_z"},"outputs":[],"source":["#데이터셋 다운로드\n","import os\n","\n","tgz_path = \"/root/.keras/datasets/102flowers.tgz\"\n","os.makedirs(os.path.dirname(tgz_path), exist_ok=True)  # 디렉토리 생성\n","\n","!wget -O {tgz_path} http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n","\n","# 파일이 제대로 다운로드되었는지 확인\n","if os.path.exists(tgz_path):\n","    print(f\"File downloaded successfully: {tgz_path}\")\n","else:\n","    print(\"File download failed!\")"]},{"cell_type":"code","source":["#추출\n","import os\n","import tarfile\n","\n","tgz_path = \"/root/.keras/datasets/102flowers.tgz\"\n","extracted_path = \"/root/.keras/datasets/102flowers_extracted\"\n","\n","if os.path.exists(tgz_path):\n","    print(f\"Extracting: {tgz_path}...\")\n","    with tarfile.open(tgz_path, \"r:gz\") as tar:\n","        tar.extractall(path=extracted_path)\n","    print(\"Extraction complete.\")\n","    print(\"Contents in extracted directory:\", os.listdir(extracted_path))\n","else:\n","    print(\"102flowers.tgz file not found!\")"],"metadata":{"id":"6fqBkOQGpWRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#라벨 다운로드\n","import os\n","\n","# 다운로드 경로 설정\n","labels_path = \"/root/.keras/datasets/102flowers_extracted/imagelabels.mat\"\n","os.makedirs(os.path.dirname(labels_path), exist_ok=True)\n","\n","# 파일 다운로드\n","!wget -O {labels_path} http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat\n","\n","# 다운로드 확인\n","if os.path.exists(labels_path):\n","    print(f\"File downloaded successfully: {labels_path}\")\n","else:\n","    print(\"File download failed!\")"],"metadata":{"id":"Ttdc3BV2pX8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#분할 정보 다운로드\n","# setid.mat 파일 다운로드\n","setid_path = \"/root/.keras/datasets/102flowers_extracted/setid.mat\"\n","os.makedirs(os.path.dirname(setid_path), exist_ok=True)\n","\n","!wget -O {setid_path} http://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat\n","\n","# 다운로드 확인\n","if os.path.exists(setid_path):\n","    print(f\"File downloaded successfully: {setid_path}\")\n","else:\n","    print(\"File download failed!\")"],"metadata":{"id":"lfjw93ENpZuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#다운로드 잘 됐는지 확인\n","import scipy.io\n","\n","# 파일 경로\n","labels_path = \"/root/.keras/datasets/102flowers_extracted/imagelabels.mat\"\n","setid_path = \"/root/.keras/datasets/102flowers_extracted/setid.mat\"\n","\n","# 라벨 파일 로드\n","if os.path.exists(labels_path):\n","    labels_data = scipy.io.loadmat(labels_path)\n","    print(\"Labels file loaded successfully!\")\n","    print(\"Keys in labels file:\", labels_data.keys())\n","else:\n","    print(f\"Labels file not found at {labels_path}!\")\n","\n","# 데이터 분할 정보 로드\n","if os.path.exists(setid_path):\n","    setid_data = scipy.io.loadmat(setid_path)\n","    print(\"SetID file loaded successfully!\")\n","    print(\"Keys in SetID file:\", setid_data.keys())\n","else:\n","    print(f\"SetID file not found at {setid_path}!\")"],"metadata":{"id":"eBTGui3ZpZ8g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#timm에서 지원하는 CoAtNet 모델 확인\n","from timm import list_models\n","\n","print(list_models(\"*coatnet*\"))"],"metadata":{"id":"h9245htspbs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#수정된 데이터 분할 코드\n","import pandas as pd\n","\n","# 라벨 및 분할 정보 로드\n","labels = labels_data[\"labels\"][0] - 1  # 라벨을 0부터 시작하도록 수정\n","train_ids = setid_data[\"trnid\"][0] - 1\n","val_ids = setid_data[\"valid\"][0] - 1\n","test_ids = setid_data[\"tstid\"][0] - 1\n","\n","# 이미지 경로 설정\n","image_dir = \"/root/.keras/datasets/102flowers_extracted/jpg\"\n","image_files = sorted([os.path.join(image_dir, f\"image_{i+1:05d}.jpg\") for i in range(len(labels))])\n","\n","# 데이터프레임 생성\n","df = pd.DataFrame({\"filename\": image_files, \"label\": labels})\n","\n","# 데이터 분할\n","train_df = df.iloc[train_ids].reset_index(drop=True)\n","val_df = df.iloc[val_ids].reset_index(drop=True)\n","test_df = df.iloc[test_ids].reset_index(drop=True)\n","\n","print(f\"Training data: {len(train_df)} samples\")\n","print(f\"Validation data: {len(val_df)} samples\")\n","print(f\"Test data: {len(test_df)} samples\")\n"],"metadata":{"id":"gFIWeF-PpdWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 전처리 함수\n","def preprocess_image(image_path, label, img_size=(224, 224)):\n","    import tensorflow as tf\n","\n","    # 이미지 읽기 및 전처리\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, img_size) / 255.0  # 정규화\n","    return image, tf.one_hot(label, 102)\n","\n","# 데이터셋 생성 함수\n","def create_dataset(df, batch_size=32, is_training=True):\n","    dataset = tf.data.Dataset.from_tensor_slices((df[\"filename\"].values, df[\"label\"].values))\n","    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","    if is_training:\n","        dataset = dataset.shuffle(1000).repeat()\n","    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n","    return dataset\n","\n","# 데이터셋 생성\n","train_dataset = create_dataset(train_df, batch_size=32, is_training=True)\n","val_dataset = create_dataset(val_df, batch_size=32, is_training=False)\n","test_dataset = create_dataset(test_df, batch_size=32, is_training=False)\n","\n","# PyTorch용 데이터 리스트 생성\n","train_paths = train_df[\"filename\"].tolist()\n","train_labels = train_df[\"label\"].tolist()\n","val_paths = val_df[\"filename\"].tolist()\n","val_labels = val_df[\"label\"].tolist()\n","test_paths = test_df[\"filename\"].tolist()\n","test_labels = test_df[\"label\"].tolist()\n","\n","print(f\"Training data: {len(train_paths)} samples\")\n","print(f\"Validation data: {len(val_paths)} samples\")\n","print(f\"Test data: {len(test_paths)} samples\")"],"metadata":{"id":"cZEwGtkapfEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#한 블록에 한 줄씩 실행해야 함\n","!pip install pillow\n","!pip install thop"],"metadata":{"id":"XQC5SSH1pgcq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from thop import profile\n","\n","# PyTorch 데이터셋 클래스 정의\n","class FlowerDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        # Pillow의 Image 클래스를 사용하여 이미지 열기\n","        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","# 이미지 전처리(transform) 정의\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# PyTorch DataLoader 생성\n","train_dataset = FlowerDataset(train_paths, train_labels, transform=transform)\n","val_dataset = FlowerDataset(val_paths, val_labels, transform=transform)\n","test_dataset = FlowerDataset(test_paths, test_labels, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","print(f\"Number of training batches: {len(train_loader)}\")\n","\n","# 모델 정의\n","from torchvision.models import resnet18\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = resnet18(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, 102)  # 102개의 클래스에 맞게 출력층 수정\n","model = model.to(device)\n","\n","# 손실 함수 및 옵티마이저\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# 평가 함수 정의\n","def evaluate_model(model, data_loader, device):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    total_loss = 0.0\n","\n","    with torch.no_grad():\n","        for images, labels in data_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","\n","            # Predictions\n","            _, preds = torch.max(outputs, 1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    # 평가 지표 계산하는 부분\n","    avg_loss = total_loss / len(data_loader)\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision = precision_score(all_labels, all_preds, average=\"weighted\")\n","    recall = recall_score(all_labels, all_preds, average=\"weighted\")\n","\n","    return avg_loss, accuracy, precision, recall\n","\n","# FLOPs 계산 함수\n","def calculate_flops(model, input_size=(1, 3, 224, 224)):\n","    dummy_input = torch.randn(*input_size).to(device)\n","    flops, params = profile(model, inputs=(dummy_input,))\n","    return flops, params\n","\n","# 모델 학습 루프\n","for epoch in range(10):  # 10 epochs\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    # Epoch마다 결과 출력\n","    print(f\"Epoch [{epoch+1}/10], Loss: {running_loss / len(train_loader):.4f}\")\n","\n","# Test에서 성능 측정\n","test_loss, test_accuracy, test_precision, test_recall = evaluate_model(model, test_loader, device)\n","print(f\"Test Loss: {test_loss:.4f}\")\n","print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","print(f\"Test Precision: {test_precision * 100:.2f}%\")\n","print(f\"Test Recall: {test_recall * 100:.2f}%\")\n","\n","# FLOPs와 파라미터 수 계산 -> 연산량 측정\n","flops, params = calculate_flops(model)\n","print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")\n","print(f\"Parameters: {params / 1e6:.2f} M\")"],"metadata":{"id":"bP6m9Ji-piOU"},"execution_count":null,"outputs":[]}]}
