{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6/wuCtQ1H7UTEd84PgjF1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZCXE3rTpw-5"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, random_split\n","from google.colab import drive\n","import os\n","import time\n","import numpy as np\n","from tqdm import tqdm\n","import pandas as pd\n","from torch.utils.data import Dataset\n","from PIL import Image"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"buCUCyNbp0Rw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = '/content/drive/MyDrive/102flowers'\n","labels_csv_path = '/content/drive/MyDrive/flowers_labeled_data.csv'"],"metadata":{"id":"lgHDyzR6p1hY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define dataset and data loaders\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","labeled_data = pd.read_csv(labels_csv_path)\n","image_paths = labeled_data['image_path'].tolist()\n","labels = (labeled_data['label'] - 1).astype(int).tolist()\n","\n","valid_indices = [i for i, label in enumerate(labels) if 0 <= label < 102]\n","image_paths = [image_paths[i] for i in valid_indices]\n","labels = [labels[i] for i in valid_indices]\n","\n","valid_image_paths = []\n","valid_labels = []\n","for img_path, label in zip(image_paths, labels):\n","    if os.path.exists(img_path):\n","        valid_image_paths.append(img_path)\n","        valid_labels.append(label)\n","\n","if not valid_image_paths:\n","    print(f\"Warning: No valid image files found in the CSV file {labels_csv_path}. Please ensure that image files are available.\")\n","    valid_image_paths = image_paths\n","    valid_labels = labels\n","\n","# Custom Dataset\n","class CustomImageDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        try:\n","            image = Image.open(self.image_paths[idx]).convert('RGB')\n","        except FileNotFoundError:\n","            raise FileNotFoundError(f\"Image at {self.image_paths[idx]} not found. Please check the file path.\")\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","# Create dataset\n","full_dataset = CustomImageDataset(image_paths=valid_image_paths, labels=valid_labels, transform=transform)"],"metadata":{"id":"CAia8FRPp5S8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split dataset into training and testi\n","train_size = int(0.8 * len(full_dataset))\n","test_size = len(full_dataset) - train_size\n","train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"],"metadata":{"id":"dzr8ekCkp6xO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load pretrained EfficientNetV2 model\n","model = models.efficientnet_v2_s(weights=None)\n","model.classifier[1] = nn.Linear(model.classifier[1].in_features, 102)"],"metadata":{"id":"XhPLRMJop8Mn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training settings\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# First move model to CPU, then GPU\n","model.to('cpu')\n","model.to(device)"],"metadata":{"id":"RAe4nJsAp8YL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Early stopping parameters\n","patience = 3\n","best_loss = np.inf\n","trigger_times = 0"],"metadata":{"id":"fTiAr2aIp98_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","epochs = 12\n","best_loss = float('inf')\n","trigger_times = 0\n","patience = 3\n","\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct_predictions = 0\n","    total_samples = 0\n","    start_time = time.time()\n","\n","    for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\")):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        labels = labels.long()\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        # Calculate accuracy\n","        _, predicted = torch.max(outputs, 1)\n","        correct_predictions += (predicted == labels).sum().item()\n","        total_samples += labels.size(0)\n","\n","        if (batch_idx + 1) % 10 == 0:\n","            print(f\"Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n","\n","    epoch_loss = running_loss / len(train_loader)\n","    epoch_accuracy = correct_predictions / total_samples\n","    epoch_time = time.time() - start_time\n","\n","    print(f\"Epoch [{epoch+1}/{epochs}] completed in {epoch_time:.2f} seconds, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n","\n","    # Early stopping check\n","    if epoch_loss < best_loss:\n","        best_loss = epoch_loss\n","        trigger_times = 0\n","    else:\n","        trigger_times += 1\n","        print(f\"Early stopping trigger times: {trigger_times}\")\n","        if trigger_times >= patience:\n","            print(\"Early stopping activated.\")\n","            break"],"metadata":{"id":"m3CAj0GRp_Ds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        labels = labels.long()\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')"],"metadata":{"id":"34hBwgRlqBIU"},"execution_count":null,"outputs":[]}]}
